{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models from Scratch: Gradient Descent\n",
    "## *Implementation*\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, guess, max_iter=10000, gamma=0.001, verbose=False):\n",
    "    \"\"\"A very simple gradient descent implementation for minimizing a function\n",
    "       \n",
    "       Parameters:\n",
    "           f -- the function f to be minimized (must be callable)\n",
    "           guess -- initial guess (tuple/list/array of values)\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    x = np.asarray(guess)\n",
    "    \n",
    "    while i < max_iter:\n",
    "        # Update x by subtracting the gradient vector at x\n",
    "        x = x - gamma*gradient(f, x)\n",
    "        \n",
    "        if verbose and i % 100 == 0:\n",
    "            print(\"Iteration {0}: x value=({1:.3f},{2:.3f}). f value={3:.3f}\".format(i, list(x)[0], list(x)[1], f(x[0], x[1])))\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(func, p):\n",
    "    \"\"\"Returns the gradient vector of func at the point p\"\"\"\n",
    "    return np.array([partial_2d(func, p, var='x'), partial_2d(func, p, var='y')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_2d(func, point, var, step=0.01):\n",
    "    \"\"\"\n",
    "    Computes the partial derivative of a function.\n",
    "    Parameters:\n",
    "        func -- Callable function of the form f(x,y)\n",
    "        point -- Tuple/list/array of x and y values (length=2)\n",
    "        var -- Variable of differentiation (must be 'x' or 'y')\n",
    "        step -- Step size\n",
    "    \"\"\"\n",
    "    x = point[0]\n",
    "    y = point[1]\n",
    "\n",
    "    if var == 'x': \n",
    "        return (func(x+step, y) - func(x-step, y)) / (2*step)\n",
    "    elif var == 'y':\n",
    "        return (func(x, y+step) - func(x, y-step)) / (2*step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Application*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll test this method on two popular [optimization_test_functions](https://en.wikipedia.org/wiki/Test_functions_for_optimization): Booth's function and a simplified version of Ackley's function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def booth(x, y):\n",
    "    \"\"\" Defines Booth's function\"\"\"\n",
    "    return (x+2*y-7)**2 + (2*x+y-5)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Booth's function is shown below. It achieves a global minimum of f(x,y)=0 at (1,3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Booth%27s_function.pdf/page1-1200px-Booth%27s_function.pdf.jpg\" align='left' height=\"350\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: f(1.00, 3.00) = 0.00\n"
     ]
    }
   ],
   "source": [
    "min_value = gradient_descent(booth, (20, 30), max_iter=10000)\n",
    "print(\"Solution: f({0:.2f}, {1:.2f}) = {2:.2f}\".format(min_value[0], min_value[1], booth(min_value[0], min_value[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ackley(x, y):\n",
    "    \"\"\"Defines Ackley's function\"\"\"\n",
    "    return -20*np.exp(-0.2*np.sqrt(0.5*(x**2 + y**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ackley's function is shown below. It achieves a global minimum of f(x,y)=-20 at (0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Ackley%27s_function.pdf/page1-1200px-Ackley%27s_function.pdf.jpg\" align='left' height=\"350\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: f(0.00, 0.00) = -20.00\n"
     ]
    }
   ],
   "source": [
    "min_value = gradient_descent(ackley, (8, 8), max_iter = 10000)\n",
    "f_value = ackley(min_value[0], min_value[1])\n",
    "print(\"Solution: f({0:.2f}, {1:.2f}) = {2:.2f}\".format(min_value[0], min_value[1], f_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
